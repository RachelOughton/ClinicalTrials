coef_baseline,
coef_arm,
coef_sex,
coef_armsex,
coef_armage,
coef_norm,
coef_unif,
coef_cat,
sd_err
){
n_tot = nrow(df_alloc)
out_temp = intercept + coef_baseline*df_alloc$baseline +
coef_arm*as.numeric(df_alloc$arm) +
coef_sex*as.numeric(df_alloc$sex) +
coef_armsex*as.numeric(df_alloc$arm)*as.numeric(df_alloc$sex)+
coef_armage*as.numeric(df_alloc$arm)*(df_alloc$age - 50)+
coef_norm*df_alloc$hid_norm +
coef_unif*df_alloc$hid_unif +
coef_cat*as.numeric(df_alloc$hid_cat) +
rnorm(n_tot, mean=0, sd=sd_err)
df_alloc$outcome = out_temp
df_alloc
}
# VERY GOOD START!
df_run100 = run_trial(df_alloc100,
coef_baseline =1,
coef_arm=-4,
coef_sex=2,
coef_armsex=-1,
coef_armage=0,
coef_norm=1,
coef_unif=2,
coef_cat=1.5,
sd_err=3)
lm_lin100 = lm(outcome ~ baseline+arm+sex+age, data=df_run100)
run_trial = function(
df_alloc,
coef_baseline,
coef_arm,
coef_sex,
coef_armsex,
coef_armage,
coef_norm,
coef_unif,
coef_cat,
sd_err
){
n_tot = nrow(df_alloc)
out_temp = coef_baseline*df_alloc$baseline +
coef_arm*as.numeric(df_alloc$arm) +
coef_sex*as.numeric(df_alloc$sex) +
coef_armsex*as.numeric(df_alloc$arm)*as.numeric(df_alloc$sex)+
coef_armage*as.numeric(df_alloc$arm)*(df_alloc$age - 50)+
coef_norm*df_alloc$hid_norm +
coef_unif*df_alloc$hid_unif +
coef_cat*as.numeric(df_alloc$hid_cat) +
rnorm(n_tot, mean=0, sd=sd_err)
df_alloc$outcome = out_temp
df_alloc
}
# VERY GOOD START!
df_run100 = run_trial(df_alloc100,
coef_baseline =1,
coef_arm=-4,
coef_sex=2,
coef_armsex=-1,
coef_armage=0,
coef_norm=1,
coef_unif=2,
coef_cat=1.5,
sd_err=3)
lm_lin100 = lm(outcome ~ baseline+arm+sex+age, data=df_run100)
lm_int100 = lm(outcome ~ (baseline+arm+sex+age)*(baseline+arm+sex+age), data=df_run100)
df_part1000 = gen_part(1000)
df_alloc1000 = df_part1000
df_alloc1000$arm = sample(c("A", "B"), size=1000, replace=T)
df_run1000 = run_trial(df_alloc100,
coef_baseline =1,
coef_arm=-4,
coef_sex=2,
coef_armsex=-1,
coef_armage=0,
coef_norm=1,
coef_unif=2,
coef_cat=1.5,
sd_err=3)
lm_lin1000 = lm(outcome ~ baseline+arm+sex+age, data=df_run1000)
lm_int1000 = lm(outcome ~ (baseline+arm+sex+age)*(baseline+arm+sex+age), data=df_run1000)
summary(lm_lin100)
summary(lm_lin1000)
summary(lm_int100)
summary(lm_int1000)
cor(df_run100$outcome[df_run100$arm==0], df_run100$baseline[df_run100$arm == 0])
cor(df_run100$outcome[df_run100$arm==1], df_run100$baseline[df_run100$arm == 1])
df_run1000 = run_trial(df_alloc100,
coef_baseline =1,
coef_arm=-4,
coef_sex=0,
coef_armsex=0,
coef_armage=1.5,
coef_norm=1,
coef_unif=2,
coef_cat=1.5,
sd_err=3)
lm_lin1000 = lm(outcome ~ baseline+arm+sex+age, data=df_run1000)
lm_int1000 = lm(outcome ~ (baseline+arm+sex+age)*(baseline+arm+sex+age), data=df_run1000)
summary(lm_lin100)
summary(lm_lin1000)
summary(lm_int100)
summary(lm_int1000)
plot(resid(lm_lin1000)~fitted(lm_lin1000), col=as.numeric(df_run1000$arm))
plot(resid(lm_int1000)~fitted(lm_int1000), col=as.numeric(df_run1000$arm))
plot(resid(lm_lin1000)~fitted(lm_lin1000), col=as.numeric(df_run1000$arm))
plot(resid(lm_int1000)~fitted(lm_int1000), col=as.numeric(df_run1000$arm))
plot(resid(lm_int1000)~df_run1000$age, col=as.numeric(df_run1000$arm))
lm_inta1000 = lm(outcome ~ baseline + arm + sex+ age +arm*age, data=df_run1000)
plot(resid(lm_inta1000)~df_run1000$age, col=as.numeric(df_run1000$arm))
summary(lm_inta1000)
plot(outcome ~ age, data=df_fun1000, col=arm)
plot(outcome ~ age, data=df_run1000, col=arm)
plot(resid(lm_int1000)~fitted(lm_int1000), col=as.numeric(df_run1000$arm))
plot(resid(lm_lin1000)~fitted(lm_lin1000), col=as.numeric(df_run1000$arm))
df_run1000 = run_trial(df_alloc100,
coef_baseline =1,
coef_arm=-4,
coef_sex=0,
coef_armsex=0,
coef_armage=2,
coef_norm=1,
coef_unif=2,
coef_cat=1.5,
sd_err=3)
df_run1000 = run_trial(df_alloc1000,
coef_baseline =1,
coef_arm=-4,
coef_sex=0,
coef_armsex=0,
coef_armage=2,
coef_norm=1,
coef_unif=2,
coef_cat=1.5,
sd_err=3)
gen_part = function(n_total){
ID = 1:n_total
sex = as.factor(sample(c("M", "F"), size = n_total, replace = T, prob = c(0.6,0.4)))
age = runif(n=n_total, min=50, max=65)
# I want the baseline measurement to be slightly higher in women than in men
# With the treatment we are looking for a reduction
baseline_int = 50 + 0.1*age
baseline = sapply(
1:n_total,
function(i){
rnorm(1, mean=baseline_int[i], sd=3)
}
)
# These will actually be added at the 'run trial' stage in shiny
hidden_norm = rnorm(n=n_total, mean=0, sd=1)
hidden_unif = runif(n=n_total, min=0, max=1)
hidden_cat = as.factor(sample(c("A", "B", "C"), size=n_total, replace=T))
df_part =  data.frame(ID = ID, sex=sex, age=age, baseline = baseline,
hid_norm = hidden_norm,
hid_unif = hidden_unif,
hid_cat = hidden_cat)
}
run_trial = function(
df_alloc,
coef_baseline=1,
coef_arm=-4,
coef_sex=0,
coef_armsex=0,
coef_armage=2,
coef_norm=1,
coef_unif=2,
coef_cat=1.3,
sd_err=3
){
n_tot = nrow(df_alloc)
out_temp = coef_baseline*df_alloc$baseline +
coef_arm*as.numeric(df_alloc$arm) +
coef_sex*as.numeric(df_alloc$sex) +
coef_armsex*as.numeric(df_alloc$arm)*as.numeric(df_alloc$sex)+
coef_armage*as.numeric(df_alloc$arm)*(df_alloc$age - 50)+
coef_norm*df_alloc$hid_norm +
coef_unif*df_alloc$hid_unif +
coef_cat*as.numeric(df_alloc$hid_cat) +
rnorm(n_tot, mean=0, sd=sd_err)
df_alloc$outcome = out_temp
df_alloc
}
df_part100 = gen_part(100)
df_alloc100 = df_part100
df_alloc100$arm = as.factor(sample(c("A", "B"), size = 100, replace=T))
df_run100 = run_trial(df_alloc100,
coef_baseline =1,
coef_arm=-4,
coef_sex=0,
coef_armsex=0,
coef_armage=2,
coef_norm=1,
coef_unif=2,
coef_cat=1.5,
sd_err=3)
lm_lin100 = lm(outcome ~ baseline+arm+sex+age, data=df_run100)
lm_int100 = lm(outcome ~ (baseline+arm+sex+age)*(baseline+arm+sex+age), data=df_run100)
lm_prop100 = lm(outcome ~ baseline + arm + age + arm:age, data=df_run100)
summary(lm_lin100)
summary(lm_lin1000)
summary(lm_int100)
summary(lm_prop100)
plot(resid(lm_lin100)~fitted(lm_lin100), col=as.numeric(df_run100$arm))
plot(resid(lm_int100)~fitted(lm_int100), col=as.numeric(df_run100$arm))
plot(resid(lm_prop100)~fitted(lm_prop100), col=as.numeric(df_run100$arm))
plot(resid(lm_prop100)~df_run100$age, col=as.numeric(df_run100$arm))
df_part1k = gen_part(1000)
df_alloc1k = df_part1k
df_alloc1k$arm = as.factor(sample(c("A", "B"), size = 1000, replace=T))
df_run1k = run_trial(df_alloc1k,
coef_baseline =1,
coef_arm=-4,
coef_sex=0,
coef_armsex=0,
coef_armage=2,
coef_norm=1,
coef_unif=2,
coef_cat=1.5,
sd_err=3)
lm_lin1k = lm(outcome ~ baseline+arm+sex+age, data=df_run1k)
lm_int1k = lm(outcome ~ (baseline+arm+sex+age)*(baseline+arm+sex+age), data=df_run1k)
lm_prop1k = lm(outcome ~ baseline + arm + age + arm:age, data=df_run1k)
summary(lm_lin1k)
summary(lm_int1k)
summary(lm_prop1k)
# Resid plot for linear looks OK-ish until you colour by arm
plot(resid(lm_lin1k)~fitted(lm_lin1k), col=as.numeric(df_run1k$arm))
plot(resid(lm_int1k)~fitted(lm_int1k), col=as.numeric(df_run1k$arm))
plot(resid(lm_prop1k)~fitted(lm_prop1k), col=as.numeric(df_run1k$arm))
plot(resid(lm_prop100)~df_run100$age, col=as.numeric(df_run100$arm))
plot(resid(lm_prop1k)~df_run1k$age, col=as.numeric(df_run1k$arm))
shiny::runApp('Library/CloudStorage/OneDrive-DurhamUniversity/AP2020_21/Teaching/2023/ClinicalTrials4H/Assignment1/R_code')
runApp('Library/CloudStorage/OneDrive-DurhamUniversity/AP2020_21/Teaching/2023/ClinicalTrials4H/Assignment1/R_code')
runApp('Library/CloudStorage/OneDrive-DurhamUniversity/AP2020_21/Teaching/2023/ClinicalTrials4H/Assignment1/R_code')
runApp('Library/CloudStorage/OneDrive-DurhamUniversity/AP2020_21/Teaching/2023/ClinicalTrials4H/Assignment1/R_code')
q()
shiny::runApp('Library/CloudStorage/OneDrive-DurhamUniversity/AP2020_21/Teaching/2023/ClinicalTrials4H/Assignment1/CT4_assignment1_dashboard')
runApp('Library/CloudStorage/OneDrive-DurhamUniversity/AP2020_21/Teaching/2023/ClinicalTrials4H/Assignment2/CT4_assignment2')
dis_level = as.factor(sample(c("Mild", "Moderate", "Severe"),
size = n_total, replace = T,
prob = c(0.5,0.3, 0.2)))
n_total = 110
dis_level = as.factor(sample(c("Mild", "Moderate", "Severe"),
size = n_total, replace = T,
prob = c(0.5,0.3, 0.2)))
summary(dis_level)
hist(rnorm(1000, mean=27.5, sd=2))
?runif
runApp('Library/CloudStorage/OneDrive-DurhamUniversity/AP2020_21/Teaching/2023/ClinicalTrials4H/Assignment2/CT4_assignment2')
# work macbook
setwd("/Users/rachelo/Documents/GitRepos/clinicaltrials")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::pdf_book")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
fun_LHSeg = function(x){(0.02 - x)^2}
fun_RHSeg = function(x){qnorm(0.975)^2*(x*(1-x))/50}
const_RHSeg = (qnorm(0.975)^2)*peg*(1-peg)/50
library(ggplot2)
ggplot() + geom_function(fun = fun_LHSeg, lty=2) + xlim(-0.1,0.2) +
geom_function(fun=fun_RHSeg) +
geom_hline(aes(yintercept = const_RHSeg), lty=3) +
xlab(expression(pi)) + ylab("") + theme_bw() +
geom_vline(xintercept = qf_eg, colour = "red", linewidth=0.4, lty=2) +
geom_vline(xintercept = peg, colour = "red", linewidth=0.8) +
geom_vline(xintercept = c(-0.0188, 0.0588), lty=3, col="red", linewidth=0.4)
ggplot() + geom_function(fun = fun_LHS, lty=2) + xlim(0.4,0.9) +
geom_function(fun=fun_RHS) +
geom_hline(aes(yintercept = const_RHS), lty=3) +
xlab(expression(pi)) + ylab("") + theme_bw() +
geom_vline(xintercept = qf_pt, colour = "red", linewidth=0.4, lty=2) +
geom_vline(xintercept = pT, colour = "red", linewidth=0.8) +
geom_vline(xintercept = stand_CI, lty=3, col="red", linewidth=0.4)
ggplot() + geom_function(fun = fun_LHS) + xlim(0.4,0.9) +
geom_function(fun=fun_RHS, lty=2) +
geom_hline(aes(yintercept = const_RHS), lty=3) +
xlab(expression(pi)) + ylab("") + theme_bw() +
geom_vline(xintercept = qf_pt, colour = "red", linewidth=0.4, lty=2) +
geom_vline(xintercept = pT, colour = "red", linewidth=0.8) +
geom_vline(xintercept = stand_CI, lty=3, col="red", linewidth=0.4)
fun_LHSeg = function(x){(0.02 - x)^2}
fun_RHSeg = function(x){qnorm(0.975)^2*(x*(1-x))/50}
const_RHSeg = (qnorm(0.975)^2)*peg*(1-peg)/50
ggplot() + geom_function(fun = fun_LHSeg) + xlim(-0.1,0.2) +
geom_function(fun=fun_RHSeg, lty=2) +
geom_hline(aes(yintercept = const_RHSeg), lty=3) +
xlab(expression(pi)) + ylab("") + theme_bw() +
geom_vline(xintercept = qf_eg, colour = "red", linewidth=0.4, lty=2) +
geom_vline(xintercept = peg, colour = "red", linewidth=0.8) +
geom_vline(xintercept = c(-0.0188, 0.0588), lty=3, col="red", linewidth=0.4)
ggplot() + geom_function(fun="logit") + xlim(0,1)
?geom_function
ggplot() + geom_function(fun=logit) + xlim(0,1)
logit(0.5)
ggplot() + geom_function(fun=glogis) + xlim(0,1)
ggplot() + geom_function(fun=qlogis) + xlim(0,1)
ggplot() + geom_function(fun=plogis) + xlim(0,1)
llog(0)
log(0)
?qlogis
ggplot() + geom_function(fun=qlogis) + xlim(0,1)
ggplot() + geom_function(fun=qlogis) + xlim(-0.01,1.01)
xvec = seq(from =0, to=1, len=100)
diffvec = 1/(xvec * (1-xvec))
plot(diffvec ~ xvec)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
library(medicaldata)
data("indo_rct")
?indo_rct
data("strep_tb")
?strep_tb
library(HSAUR)
data(respiratory)
?respiratory
c1 = c(1,1,4,1,3,2)
any(c1, c(1,4))
?any
c1 %in% c(1,4)
resp_04 = respiratory[respiratory$month %in% c(0,4),]
summary(resp_04)
resp_4 = respiratory[respiratory$month %in% c(4),]
summary(resp_4)
model1 = glm(status ~ centre + treatment + sex, data=resp4, family = binomial(link='logit'))
resp_4 = respiratory[respiratory$month %in% c(4),]
model1 = glm(status ~ centre + treatment + sex, data=resp4, family = binomial(link='logit'))
model1 = glm(status ~ centre + treatment + sex, data=resp_4, family = binomial(link='logit'))
summary(model1)
model1 = glm(status ~ centre + treatment + sex + age, data=resp_4, family = binomial(link='logit'))
summary(model1)
resp_4$status0 = sapply(
1:nrow(resp_04),
function(i){
resp_04$status[(resp_04$month==0)&(resp_04$subject = resp_4$subject[i])]
})
resp_4$status0 = sapply(
1:nrow(resp_04),
function(i){
resp_04$status[(as.numeric(resp_04$month)==0)&(resp_04$subject = resp_4$subject[i])]
})
resp_4$status0 = sapply(
1:nrow(resp_04),
function(i){
resp_04$status[(as.numeric(resp_04$month)==0)&(as.numeric(resp_04$subject) = as.numeric(resp_4$subject)[i])]
})
resp_4$status0 = sapply(
)
resp_4$status0 = sapply(
resp_4$status0 = resp_04$status[resp_04$month==0]
resp_4$status0 = resp_04$status[resp_04$month==0]
resp_4
resp_04$subject[resp_04$month==0]
resp_04$subject[resp_04$month==4]
model1 = glm(status ~ centre + treatment + sex + age + status0, data=resp_4, family = binomial(link='logit'))
summary(model1)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
-0.839+1.274+1.085+1.726
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
exp(3.246)
?exp
exp(3.246) / (1+exp(3.246))
exp(-0.839 + 1.085)
exp(1.279)
exp(1.279)/(1+ exp(1.279))
1.085 - qnorm(0.975)*0.474
qnorm(0.975)
1.085 + qnorm(0.975)*0.474
exp(0.156)
exp(02.01)
exp(02.014)
summary(model1)
model2 = glm(status ~ centre + treatment +  status0,
family = binomial(link='logit'), data=resp_4)
summary(model2)
model2 = glm(status ~ centre + treatment +  status0 + age,
family = binomial(link='logit'), data=resp_4)
summary(model2)
model2 = glm(status ~ centre + treatment +  status0,
family = binomial(link='logit'), data=resp_4)
summary(model2)
1.024 - qnorm(0.975)*0.4532
1.024 + qnorm(0.975)*0.4532
exp(1.024 - qnorm(0.975)*0.4532)
exp(1.024 + qnorm(0.975)*0.4532)
exp(-1.643 + 1.101 + 1.024 + 1.729)
-1.643 + 1.101 + 1.024 + 1.729
exp(2.211)/(1+exp(2.211))
-1.643 + 1.024
exp(-0.619)
exp(-0.619)/(1+exp(-0.619))
exp(-1.643)
exp(-1.643)/(1+exp(-1.643))
install.packages("separationplot")
fitted(model2)
library(separationplot)
separationplot(fitted(model1), resp_4$status)
separationplot(as.numeric(fitted(model1)), resp_4$status)
separationplot(as.numeric(fitted(model1)), as.numeric(resp_4$status))
separationplot(fitted(model1), as.numeric(resp_4$status))
resp_4$status
as.numeric(resp_4$status)
fitted(model1)
separationplot(fitted(model1), as.numeric(resp_4$status)-1)
as.numeric(resp_4$status)-1
?separation plot
?separationplot
separationplot(fitted(model2), as.numeric(resp_4$status)-1)
separationplot(fitted(model2), as.numeric(resp_4$status)-1)
model3 = glm(status ~ (centre + treatment +  status0):(centre + treatment +  status0),
family = binomial(link='logit'), data=resp_4)
summary(model3)
separationplot(fitted(model3), as.numeric(resp_4$status)-1)
fit1 <- glm(inmetro ~ percollege, data = midwest, family = binomial)
midwest$f1 <- predict(fit1, midwest, type = "response")
separationplot(pred = midwest$f1, actual = midwest$inmetro)
separationplot(pred = midwest$f1, actual = midwest$inmetro)
library(separationplot)
fit3 <- glm(inmetro ~ category, data = midwest, family = binomial)
midwest$f3 <- predict(fit3, midwest, type = "response")
separationplot(midwest$f3, midwest$inmetro)
summary(fit1)
summary(midwest)
lm_mwfull = lm(inmetro ~ ., data=midwest)
lm_mwfull = glm(inmetro ~ ., data=midwest, family = binomial(li))
lm_mwfull = glm(inmetro ~ ., data=midwest, family = binomial(link = 'logit'))
ncol(midwest)
lm_mwfull = glm(inmetro ~ ., data=midwest[,1:27], family = binomial(link = 'logit'))
lm_mwfull = glm(inmetro ~ ., data=midwest[,4:27], family = binomial(link = 'logit'))
lm_mwfull = glm(inmetro ~ ., data=midwest[,24:27], family = binomial(link = 'logit'))
summary(lm_mwfull)
lm_mwfull = glm(inmetro ~ ., data=midwest[,20:27], family = binomial(link = 'logit'))
lm_mwfull = glm(inmetro ~ ., data=midwest[,21:27], family = binomial(link = 'logit'))
lm_mwfull = glm(inmetro ~ ., data=midwest[,22:27], family = binomial(link = 'logit'))
summary(lm_mwfull)
glm_mw_rubbish = glm(inmetro ~ percpovertyknown + percadultpoverty + percbelowpoverty,data=midwest, family = binomial(link = 'logit'))
summary(glm_mw_rubbish)
glm_mw_rubbish = glm(inmetro ~ percpovertyknown ,data=midwest, family = binomial(link = 'logit'))
summary(glm_mw_rubbish)
midwest$f_rubbish <- predict(glm_mw_rubbish, midwest, type = "response")
separationplot(midwest$f_rubbish, midwest$inmetro)
glm_mw_rubbish = glm(inmetro ~ percpovertyknown, data=midwest, family = binomial(link = 'logit'))
midwest$f_rubbish <- predict(glm_mw_rubbish, midwest, type = "response")
separationplot(midwest$f_rubbish, midwest$inmetro)
glm_mw_rubbish = glm(inmetro ~ percpovertyknown + area, data=midwest, family = binomial(link = 'logit'))
midwest$f_rubbish <- predict(glm_mw_rubbish, midwest, type = "response")
separationplot(midwest$f_rubbish, midwest$inmetro)
?separationplot
separationplot(midwest$f_rubbish, midwest$inmetro, line=T)
separationplot(midwest$f_rubbish, midwest$inmetro, line=F)
separationplot(midwest$f_rubbish, midwest$inmetro, show.expected = T)
separationplot(midwest$f3, midwest$inmetro, show.expected = T)
separationplot(pred = midwest$f1, actual = midwest$inmetro, show.expected = T)
?separationplot
1. **The better the separation, the better the model**. The first plot shows a reasonably good model, where the density of red lines approximately follows the line of fitted probability. However, the line is fairly shallow, and the red lines are fairly scattered. The second plot shows a perfect model. The fitted probability jumps from 0 to 1 at around 0.7 (shown by the black triangle), and there is perfect separation between the ones and zeroes.
library(MASS)
set.seed(1)
Sigma <- matrix(c(1,0.78,0.78,1),2,2)
a<-(mvrnorm(n=500, rep(0, 2), Sigma))
a[,2][a[,2]>0.75]<-1
a[,2][a[,2]<=0.75]<-0
a[,1]<-a[,1]-min(a[,1])
a[,1]<-a[,1]/max(a[,1])
cor(a) # should be 0.55
model1<-glm(a[,2]~a[,1], family=binomial(link = "logit"))
library(Hmisc)
somers2(model1$fitted.values, model1$y)
separationplot(pred=model1$fitted.values, actual=model1$y, type="rect",
line=TRUE, show.expected=TRUE, heading="Example 1")
separationplot(pred=model1$fitted.values, actual=model1$y, type="rect",
line=TRUE, show.expected=TRUE, heading="Example 1")
mw_eg = data.frame(
inmetro = midwest$inmetro,
percollege = midwest$percollege,
unif1 = runif(n=nrow(midwest), min=0, max=1),
cat1 = sample(c(0,1,2,3), size=nrow(midwest), replace=T)
)
glm_eg = glm(inmetro ~ ., data=mw_eg, family=binomial(link = 'logit'))
summary(glm_eg)
separationplot(mw_eg$fit, mw_eg$inmetro, show.expected = T)
mw_eg$fit
mw_eg$fit <- predict(glm_eg, mw_eg, type = "response")
separationplot(mw_eg$fit, mw_eg$inmetro, show.expected = T)
fit1 = predict(model1, resp_4, type = "response")
model1 = glm(status ~ centre + treatment + sex + age + status0,
family = binomial(link='logit'), data=resp_4)
summary(model1)
fit1 = predict(model1, resp_4, type = "response")
separationplot(fit1, resp_4$status)
separationplot(fit1, (as.numeric(resp_4$status)-1) )
fit2 = predict(model2, resp_4, type = "response")
separationplot(fit2, (as.numeric(resp_4$status)-1) )
bookdown::render_book("index.Rmd", "bookdown::gitbook")
?summarize
?dplyr::summarize
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
