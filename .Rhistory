summary(lm_x)
set.seed(60007)
n <- 15
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
# Generate a matrix 40 draws from this distribution
x_mat = mvrnorm(n=20, mu=1:n, Sigma=Sigma)
# Turn it into a data frame and name the columns x1 to x<n>
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:n)
# Create a dependent variable y, made by a linear combination of x variables
# y is deliberately not dependent on x3
attach(x_df)
Sigma
set.seed(60007)
n <- 15
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
# Generate a matrix 40 draws from this distribution
x_mat = mvrnorm(n=20, mu=rep(1,n), Sigma=Sigma)
# Turn it into a data frame and name the columns x1 to x<n>
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:n)
# Create a dependent variable y, made by a linear combination of x variables
# y is deliberately not dependent on x3
attach(x_df)
# y is just the sum of all the x variables, plus some random error
x_df$y = rowSums(x_df) + rnorm(n=20, mean=0, sd=0.1)
?lm
cat(sprintf("x%g+", 1:15))
lm_x = lm(y~x1+ x2+ x3+ x4+ x5+ x6+ x7+ x8+ x9+ x10+ x11+ x12+ x13+ x14+ x15, data=x_df)
summary(lm_x)
Sigma[3,]
?princomp
pc_x = princomp(x_df[,(n+1)])
pc_x
pc_x = princomp(x_df[,-(n+1)])
pc_x
set.seed(60005)
n <- 15
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
Sigma
# Generate a matrix 40 draws from this distribution
x_mat = mvrnorm(n=20, mu=rep(1,n), Sigma=Sigma)
# Turn it into a data frame and name the columns x1 to x<n>
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:n)
# Create a dependent variable y, made by a linear combination of x variables
attach(x_df)
# y is just the sum of all the x variables, plus some random error
x_df$y = rowSums(x_df) + rnorm(n=20, mean=0, sd=0.1)
lm_x = lm(y~x1+ x2+ x3+ x4+ x5+ x6+ x7+ x8+ x9+ x10+ x11+ x12+ x13+ x14+ x15, data=x_df)
summary(lm_x)
set.seed(6005)
n <- 15
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
# Generate a matrix 40 draws from this distribution
x_mat = mvrnorm(n=20, mu=rep(1,n), Sigma=Sigma)
# Turn it into a data frame and name the columns x1 to x<n>
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:n)
# Create a dependent variable y, made by a linear combination of x variables
attach(x_df)
# y is just the sum of all the x variables, plus some random error
x_df$y = rowSums(x_df) + rnorm(n=20, mean=0, sd=0.1)
lm_x = lm(y~x1+ x2+ x3+ x4+ x5+ x6+ x7+ x8+ x9+ x10+ x11+ x12+ x13+ x14+ x15, data=x_df)
summary(lm_x)
Sigma
pc_x = princomp(x_df[,-(n+1)])
summary(pc_x)
screeplot(pc_x)
loadings(pc_x)
load_pcx = loadings(pc_x)
class(load_pcx)
names(load_pcx)
load_pcx%*%x_df[,-16]
attr(load_pcx, "Loadings")
?loadings
pc_x$loadings
load_pcx = pc_x$loadings
class(load_pcx)
biplot(pc_x)
as.matrix(load_pcx)
as.matrix(load_pcx)%*%x_mat
dim(as.matrix(load_pcx))
dim(x_mat)
t(x_mat)%*%as.matrix(load_pcx)
dim(t(x_mat))
dim(x_mat)
pc_x_data = x_mat%*%as.matrix(load_pcx)
cor(pc_x_data)
names(pc_x_data)
class(pc_x_data)
pc_x_df = as.data.frame(pc_x_mat)
pc_x_mat = x_mat%*%as.matrix(load_pcx)
# You can see that now the correlations are [almost] zero
# This therefore solves our problem of multicollinearity
cor(pc_x_mat)
pc_x_df = as.data.frame(pc_x_mat)
names(pc_x_df) = sprintf("pc%g", 1:15)
pc_x_df
pc_x
summary(pc_x)
pc_x_df$y = x_df$y
cat(sprintf("pc%g +", 1:9))
pc_lm = lm(y ~ pc1 + pc2 + pc3 + pc4 + pc5 + pc6 + pc7 + pc8 + pc9, data = pc_x_df)
summary(pc_lm)
cat(sprintf("pc%g +", 1:15))
pc_lm_full = lm(y~pc1 + pc2 + pc3 + pc4 + pc5 + pc6 + pc7 + pc8 + pc9 + pc10 + pc11 + pc12 + pc13 + pc14 + pc15, data=pc_x_df)
summary(pc_lm_full)
summary(pc_x)
pc_lm_red = lm(y~pc1 + pc2 + pc3 + pc4 + pc5 + pc6 + pc7 + pc8 + pc9 + pc10 + pc11 + pc12, data=pc_x_df)
summary(pc_lm_red)
summary(lm_x)
pc_x$loadings
library(ncdf4)
library(dplyr)
library(ggplot2)
library(scales)
library(maps)
library(shiny)
getwd()
nc = nc_open("Downloads/IBTrACS.NA.v04r00.nc")
world <- map_data("world")
# Extract lat/lon arrays
lats <- ncvar_get(nc, 'lat')
lons <- ncvar_get(nc, 'lon')
max(lons, na.rm=TRUE) # East
min(lons,na.rm=TRUE) # West
max(lats, na.rm=TRUE) # North
min(lats, na.rm=TRUE) # South
# Get storm IDs
storm_ids <- ncvar_get(nc, 'sid')
# Initialize empty list to store tracks
tracks <- vector('list', length(unique(storm_ids)))
# Loop through storm IDs
for(i in 1:length(unique(storm_ids))) {
# Index lat/lon arrays to extract track
track_lats <- lats[,i]
track_lons <- lons[,i]
# Add to list
tracks[[i]] <- data.frame(lat = track_lats,
lon = track_lons)
# Remove NAs
tracks[[i]] <- na.omit(tracks[[i]])
}
# A handful of tracks
plot(tracks[[1]][,2],
tracks[[1]][,1],
type = 'l',
xlab = 'Longitude',
ylab = 'Latitude',
xlim = c(86,94),
ylim = c(20,28))
lines(tracks[[2]][,2],
tracks[[2]][,1],
col='red')
lines(tracks[[3]][,2],
tracks[[3]][,1],
col='blue')
lines(tracks[[4]][,2],
tracks[[4]][,1],
col='purple')
lines(x=world$long,y=world$lat,
xlim=c(86,94),
ylim=c(20,28),
type="p",pch=16,cex=0.01,col="grey")
dim(tracks)
# Extract lat/lon arrays
lats <- ncvar_get(nc, 'lat')
lons <- ncvar_get(nc, 'lon')
max(lons, na.rm=TRUE) # East
min(lons,na.rm=TRUE) # West
max(lats, na.rm=TRUE) # North
min(lats, na.rm=TRUE) # South
dim(lats)
lats[1:10,1:10]
max(lons, na.rm=TRUE) # East
min(lons,na.rm=TRUE) # West
max(lats, na.rm=TRUE) # North
min(lats, na.rm=TRUE) # South
# Get storm IDs
storm_ids <- ncvar_get(nc, 'sid')
summary(storm_ids)
storm_ids[1:10]
length(tracks)
# Loop through storm IDs
for(i in 1:length(unique(storm_ids))) {
# Index lat/lon arrays to extract track
track_lats <- lats[,i]
track_lons <- lons[,i]
# Add to list
tracks[[i]] <- data.frame(lat = track_lats,
lon = track_lons)
# Remove NAs
tracks[[i]] <- na.omit(tracks[[i]])
}
tracks[1]
max.lon = max(lons, na.rm=TRUE) # East
min.lon = min(lons,na.rm=TRUE) # West
max.lat = max(lats, na.rm=TRUE) # North
min.lat = min(lats, na.rm=TRUE) # South
# A handful of tracks
plot(tracks[[1]][,2],
tracks[[1]][,1],
type = 'l',
xlab = 'Longitude',
ylab = 'Latitude',
xlim = c(min.lon, max.lon),
ylim = c(min.lat, max.lat))
lines(tracks[[2]][,2],
tracks[[2]][,1],
col='red')
lines(tracks[[3]][,2],
tracks[[3]][,1],
col='blue')
lines(tracks[[4]][,2],
tracks[[4]][,1],
col='purple')
lines(x=world$long,y=world$lat,
xlim=c(86,94),
ylim=c(20,28),
type="p",pch=16,cex=0.01,col="grey")
tracks[[3]]
tracks[[4]]
tracks[[5]]
lines(x=world$long,y=world$lat,
xlim=c(86,94),
ylim=c(20,28),
type="p",pch=16,cex=0.01,col="grey")
# All the tracks
plot(tracks[[1]][,2],
tracks[[1]][,1],
type = 'l',
xlab = 'Longitude',
ylab = 'Latitude',
xlim = c(86,94),
ylim = c(20,28),
col = 'blue')
lines(tracks[[2]][,2],
tracks[[2]][,1],
col='red')
lines(tracks[[3]][,2],
tracks[[3]][,1],
col='blue')
lines(tracks[[4]][,2],
tracks[[4]][,1],
col='purple')
lines(x=world$long,y=world$lat,
xlim=c(86,94),
ylim=c(20,28),
type="p",pch=16,cex=0.01)
season <- ncvar_get(nc,"season")
season
for (i in 1:length(unique(storm_ids))){
lines(tracks[[i]][,2],
tracks[[i]][,1],
col=alpha(season[i],0.2),scale_color_gradient(low="blue", high="red"))
}
class(season)
plot(tracks[[1]][,2],
tracks[[1]][,1],
type = 'l',
xlab = 'Longitude',
ylab = 'Latitude',
xlim = c(min.lon, max.lon),
ylim = c(min.lat, max.lat))
for (i in 2:length(unique(storm_ids))){
lines(tracks[[i]][,2],
tracks[[i]][,1])
}
class(season[1])
class(season[2])
library(paletteer)
install.packages("paletteer")
library(paletteer)
nColor <- 20
colors <- paletteer_c(package = "viridis", palette = "inferno", n = nColor)
library(viridus)
library(viridis)
colors
?paletter_c
?paletteer_c
colors <- paletteer_c(palette = "inferno", n = nColor)
colors <- paletteer_c(palette = "viridis::inferno", n = nColor)
# Transform the numeric variable in bins
rank <- as.factor( as.numeric( cut(iris$Petal.Width, nColor)))
# Scatterplot with color gradient
plot(
x = iris$Petal.Length,
y = iris$Petal.Width,
bg = colors[ rank ],
cex = 3,
pch=21
)
nColor_seas <- 20
colors_seas <- paletteer_c(palette = "viridis::inferno", n = nColor_seas)
# Transform the numeric variable in bins
rank_seas <- as.factor( as.numeric( cut(season, nColor)))
nColor_seas <- 20
colors_seas <- paletteer_c(palette = "viridis::inferno", n = nColor_seas)
# Transform the numeric variable in bins
rank_seas <- as.factor( as.numeric( cut(season, nColor)))
plot(tracks[[1]][,2],
tracks[[1]][,1],
type = 'l',
col = colors_seas[rank_seas[1]],
xlab = 'Longitude',
ylab = 'Latitude',
xlim = c(min.lon, max.lon),
ylim = c(min.lat, max.lat))
for (i in 2:length(unique(storm_ids))){
lines(tracks[[i]][,2],
tracks[[i]][,1],
col = colors_seas[rank_seas[i]])
}
plot(tracks[[1]][,2],
tracks[[1]][,1],
type = 'l',
col = colors_seas[rank_seas[1]],
xlab = 'Longitude',
ylab = 'Latitude',
xlim = c(min.lon, max.lon),
ylim = c(min.lat, max.lat))
for (i in 2:length(unique(storm_ids))){
lines(tracks[[i]][,2],
tracks[[i]][,1],
col = alpha(colors_seas[rank_seas[i]]), 0.2)
}
?alpha
plot(tracks[[1]][,2],
tracks[[1]][,1],
type = 'l',
col = colors_seas[rank_seas[1]],
xlab = 'Longitude',
ylab = 'Latitude',
xlim = c(min.lon, max.lon),
ylim = c(min.lat, max.lat))
for (i in 2:length(unique(storm_ids))){
lines(tracks[[i]][,2],
tracks[[i]][,1],
col = alpha(colors_seas[rank_seas[i]], 0.2))
}
pres <-  ncvar_get(nc, "usa_pres")
dim(pres)
pres_usa <-  ncvar_get(nc, "usa_pres")
dim(pres_usa)
# so for storm id[1]
pres_df <- data.frame(
id = rep(1, length(na.omit(lat[,1]))),
lat = na.omit(lat[,1]),
long = na.omit(long[,1]),
time = na.omit(time[,1]),
# The following line finds the status values that corresponds to
# latitudes that aren't NA, so the same rows we have for the other
# variables
pres = pres_usa[,1][!is.na(lat[,1])]
)
lat <- ncvar_get(nc, "lat")
nlat <- dim(lat)
long <- ncvar_get(nc, "lon")
nlon <- dim(long)
time <- ncvar_get(nc, "time")
nt <- dim(time)
pres_usa <-  ncvar_get(nc, "usa_pres")
dim(pres_usa) # pressure has 360 rows and 2344 columns, so a column for each storm, a row for each time point
# so for storm id[1]
pres_df <- data.frame(
id = rep(1, length(na.omit(lat[,1]))),
lat = na.omit(lat[,1]),
long = na.omit(long[,1]),
time = na.omit(time[,1]),
# The following line finds the status values that corresponds to
# latitudes that aren't NA, so the same rows we have for the other
# variables
pres = pres_usa[,1][!is.na(lat[,1])]
)
summary(pres_usa)
dim(pres_df)
summary(pres_df)
summary(pres_usa[,1])
# collecting storms 1 to 1000
for (i in 2:1000){
df_i <- data.frame(
id = rep(i, length(na.omit(lat[,i]))),
lat = na.omit(lat[,i]),
long = na.omit(long[,i]),
time = na.omit(time[,i]),
pres = pres_usa[,i][!is.na(lat[,i])]
)
pres_df = rbind(pres_df, df_i)
}
summary(pres_df$pres)
ggworldplot = ggplot(data=world, aes(x=long, y=lat)) +
geom_path(aes(group = group)) +
theme_bw() + # this gets rid of the grey background
xlab("Longitude") +
ylab("Latitude")
ggworldplot +
geom_path(data = pres_df[!is.na(pres_df$pres),],
aes(x=long, y=lat, group=id, col = pres), alpha=0.25, lwd=1) +
xlim(range(long, na.rm=T)) + ylim(range(lat, na.rm=T))+
scale_color_gradient(low="blue", high="red")
library(HSAUR)
data(BCG)
summary(BCG)
?BCG
data(aspirin)
?aspirin
?epilepsy
?mastectomy
?plasma
?prostate
library(faraway)
?prostate
?plasma
?respiratory
?smoking
library(lme4)
?sleepstudy
?Penicillin
library(MASS)
?Aids2
?Cushings
?Melanoma
?VA
?anorexia
data(gehan)
?gehan
?leuk
?wtloss
?indo_rct
library(medicaldata)
?indo_rct
library(nlme)
?Ovary
?PBG
library(rpart)
?kyphosis
?strep_tb
num_tb = (0.691 - 0.327)
den_tb = sqrt(0.514*(1-0.514)+(1/52 + 1/55))
num_tb / den_tb
den_tb
(1/52 + 1/55)
(1/52 + 1/55)*(1-0.514)
(1/52 + 1/55)*(1-0.514)*0.514
sqrt((1/52 + 1/55)*(1-0.514)*0.514)
den_tb = sqrt((1/52 + 1/55)*(1-0.514)*0.514)
num_tb / den_tb
z_tb = num_tb/den_tb
z_tb
pnorm(z_tb, mean=0, sd=1)
2*(1-pnorm(3.765, mean=0, sd=1))
0.514*52
0.514*55
tab_exp  = table(strep_tb[,c(2,13)])
tab_exp
tab_exp[1,1]
tab_exp[1,1] = (1-0.514)*55
tab_exp[1,2] = (0.514)*55
tab_exp[2,1] = (1-0.514)*52
tab_exp[2,2] = (0.514)*52
tab_exp
# work macbook
setwd("/Users/rachelo/Documents/GitRepos/clinicaltrials")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
?apply
sum_chi_sq = 0 # set a running total going
# in the following, tab_obs is the table of observed values and
# tab_exp is the table of expected values
for (i in 1:2){
for (j in 1:2){
tmp = ((tab_obs[i,j] - tab_exp[i,j])^2)/tab_exp[i,j]
sum_chi_sq = sum_chi_sq + tmp
}
}
tab_obs = table(strep_tb[,c(2,13)])
tab_obs
# in the following, tab_obs is the table of observed values and
# tab_exp is the table of expected values
for (i in 1:2){
for (j in 1:2){
tmp = ((tab_obs[i,j] - tab_exp[i,j])^2)/tab_exp[i,j]
sum_chi_sq = sum_chi_sq + tmp
}
}
sum_chi_sq
sqrt(sum_chi_sq)
pchisq(sum_chi_sq, df=1)
1-pchisq(sum_chi_sq, df=1)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
curve(dexp(x,lambda=1), xlim=c(0,10)
)
?dexp
curve(function(x){dexp(x,rate = 1)), xlim=c(0,10))
curve(function(x){dexp(x,rate = 1), xlim=c(0,10))
curve(function(x){dexp(x,rate = 1))
curve(function(x){dexp(x,rate = 1)
curve(function(x){dexp(x,rate = 1))
curve(function(x){dexp(x,rate = 1)}, xlim=c(0,10))
vec = seq(0,10, by=0.1)
exp_vec = dexp(vec, rate=1)
plot(exp_vec~vec)
fun_vec = vec*exp(-vec)
plot(fun_vec ~ vec)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
