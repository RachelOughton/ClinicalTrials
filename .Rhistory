T_mich = 4*1.5*6
T_epip =  3*5*1.5 + 2*3
L2_epip = 20*10
M = 8*(56/16)
M_CT = 3
P = 30 + 0.25*30 # includes paternity cover for JP
A0 = 9
E = 50
E_CT = 50 # fairly arbitrary - setting and marking coursework for CT4
X = 100
WC = 10
workload_tot = T_mich + T_epip + L2_epip + M + M_CT + P + A0 +E + E_CT + X + WC
workload_scaled = workload_tot / 0.6
workload_scaled
T_mich = 4*1.5*6    # DSSC tutorials michaelmas + easter
T_epip =  3*4*1.5 + 2*3   # Stats modelling + CT4 practicals
L2_epip = 20*10     # CT4 lectures
M = 8*(56/16)    # Decision Theory (assumes both terms?)
M_michonly = 4*(56/16) # DT marking if only Michaelmas
M_CT = 3         # Assignment marking for CT4 - suspect an underestimate!
P = 30 + 0.25*30 # My own project plus paternity cover for JP
A0 = 9           # Advisees
E = 50           # exam and project marking
E_CT = 50        # fairly arbitrary - setting and marking coursework for CT4
X = 100          # Extra stuff
WC = 10          # Workload committee
workload_tot = T_mich + T_epip + L2_epip + M + M_CT + P + A0 +E + E_CT + X + WC
workload_scaled = workload_tot / 0.6
T_mich = 4*1.5*6    # DSSC tutorials michaelmas + easter
T_epip =  3*4*1.5 + 2*3   # Stats modelling + CT4 practicals
L2_epip = 20*10     # CT4 lectures
M = 8*(56/16)    # Decision Theory (assumes both terms?)
M_michonly = 4*(56/16) # DT marking if only Michaelmas
M_CT = 3         # Assignment marking for CT4 - suspect an underestimate!
P = 30 + 0.25*30 # My own project plus paternity cover for JP
A0 = 9           # Advisees
E = 50           # exam and project marking
E_CT = 50        # fairly arbitrary - setting and marking coursework for CT4
X = 100          # Extra stuff
WC = 10          # Workload committee
workload_tot = T_mich + T_epip + L2_epip + M + M_CT + P + A0 +E + E_CT + X + WC
workload_scaled = workload_tot / 0.6
workload_tot_DTmich = T_mich + T_epip + L2_epip + M_michonly + M_CT + P + A0 +E + E_CT + X + WC
workload_scaled_DTmich = workload_tot_DTmich/0.6
workload_scaled
workload_scaled_DTmich
q()
library(maps)
?maps
data("world2MapEnv")
class(world2MapEnv)
data(world2MapEnv)
class(world2MapEnv)
class(world)
data(world)
data("world")
map('world', fill = TRUE, col = 1:10, wrap=c(-180,180) )
map('world', wrap=c(-180,180) )
world = map_data("world")
library(ggplot2)
world = map_data("world")
names(world)
?aes
ggplot(data=world, aes(x=long, y=lat, group = group)) + geom_path()
max(world$group)
?plot
plot(lat~long, data = world[world$group==1,])
plot(lat~long, data = world[world$group==1,], type = "l")
plot(lat~long, data = world[world$group==1,], type = "l", xlim=c(-180,180))
summary(world)
plot(lat~long, data = world[world$group==1,],
type = "l", xlim=c(-180,191), ylim = c(-86, 84))
?lines
for (i in 2:1627){
lines(world$long[world$group==i], world$lat[world$group=2])
for (i in 2:1627){
lines(world$long[world$group==i], world$lat[world$group==i])
}
ggworldplot = ggplot(data=world, aes(x=long, y=lat, group = group)) +
geom_path() +
theme_bw() +
xlab("Longitude") +
ylab("Latitude")
ggworldplot
storm_df = data.frame(
long = rnorm(100, mean=-50, sd=10),
lat = rnorm(100, mean=0, sd=30),
pressure = rnorm(100, mean=10, sd=10)
)
ggworldplot +
geom_point(aes(x=long, y=lat, fill=pressure), alpha=0.5)+
scale_fill_continuous(type = "viridis")
storm_df
ggworldplot +
geom_point(data = storm_df, aes(x=long, y=lat, fill=pressure), alpha=0.5)+
scale_fill_continuous(type = "viridis")
ggworldplot = ggplot(data=world, aes(x=long, y=lat)) +
geom_path(aes(group = group)) +
theme_bw() + # this gets rid of the grey background
xlab("Longitude") +
ylab("Latitude")
ggworldplot
storm_df = data.frame(
long = rnorm(100, mean=-50, sd=10),
lat = rnorm(100, mean=0, sd=30),
pressure = rnorm(100, mean=10, sd=10)
)
ggworldplot +
geom_point(data = storm_df, aes(x=long, y=lat, fill=pressure), alpha=0.5)+
scale_fill_continuous(type = "viridis")
ggworldplot +
geom_point(data = storm_df, aes(x=long, y=lat, col=pressure), alpha=0.5)+
scale_color_continuous(type = "viridis")
storm_df = data.frame(
long = rnorm(100, mean=-50, sd=50),
lat = rnorm(100, mean=0, sd=10),
pressure = rnorm(100, mean=10, sd=10)
)
ggworldplot +
geom_point(data = storm_df, aes(x=long, y=lat, col=pressure), alpha=0.5)+
scale_color_continuous(type = "viridis")
storm_df = data.frame(
long = rnorm(100, mean=-50, sd=5),
lat = rnorm(100, mean=0, sd=10),
pressure = rnorm(100, mean=10, sd=10)
)
ggworldplot +
geom_point(data = storm_df, aes(x=long, y=lat, col=pressure), alpha=0.5)+
scale_color_continuous(type = "viridis")
storm_df = data.frame(
long = rnorm(100, mean=-50, sd=5),
lat = rnorm(100, mean=0, sd=10),
pressure = rnorm(100, mean=100, sd=10)
)
ggworldplot +
geom_point(data = storm_df, aes(x=long, y=lat, col=pressure),
alpha=0.5) +
scale_color_continuous(type = "viridis")
ggworldplot + # add this on to the world map
geom_point(data = storm_df, aes(x=long, y=lat, col=pressure),
alpha=0.3) +
scale_color_continuous(type = "viridis")
ggworldplot + # add this on to the world map
geom_point(data = storm_df, aes(x=long, y=lat, col=pressure),
alpha=0.4) +
scale_color_continuous(type = "viridis")
library(mvnorm)
library(MASS)
?mnrnorm
?mvrnorm
set.seed(60007)
x_cor = diag(4)
for (i in 1:3){
for (j in 2:4){
random_corr = runif(1, min=0, max=1)
x_cor[i,j] = random_corr
x_cor[j,i] = random_corr
}
}
x_mat = mvrnorm(n=20, mu=)
x_cor
is.pd(x_cor)
is.positive.definite(x_cor)
library(matrixcalc)
require(matrixcalc)
install.packages("matrixcalc")
require(matrixcalc)
is.positive.definite(x_cor)
n <- 4
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
is.positive.definite(Sigma)
Sigma
set.seed(60007)
n <- 4
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
Sigma
x_mat = mvrnorm(n=20, mu=1, Sigma=Sigma)
x_mat = mvrnorm(n=20, mu=c(1,2,3,4), Sigma=Sigma)
set.seed(60007)
n <- 4
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
x_mat = mvrnorm(n=20, mu=1:4, Sigma=Sigma)
x_mat
names(x_df) = sprintf("x%g", 1:4)
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:4)
x_df
# Create a dependent variable y, made by a linear combination of x variables
# y is deliberately not dependent on x3
attach(x_df)
x_df$y = 3*x1 + 2*x2 - x4
x_df
lm_x = lm(y~x1+x2+x3+x4, data=x_df)
summary(lm_x)
# Create a dependent variable y, made by a linear combination of x variables
# y is deliberately not dependent on x3
attach(x_df)
x_df$y = 3*x1 + 2*x2 - x4 + rnorm(n=20, mean=0, sd=0.1)
lm_x = lm(y~x1+x2+x3+x4, data=x_df)
summary(lm_x)
set.seed(60007)
n <- 15
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
# Generate a matrix 40 draws from this distribution
x_mat = mvrnorm(n=20, mu=1:n, Sigma=Sigma)
# Turn it into a data frame and name the columns x1 to x<n>
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:n)
# Create a dependent variable y, made by a linear combination of x variables
# y is deliberately not dependent on x3
attach(x_df)
Sigma
set.seed(60007)
n <- 15
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
# Generate a matrix 40 draws from this distribution
x_mat = mvrnorm(n=20, mu=rep(1,n), Sigma=Sigma)
# Turn it into a data frame and name the columns x1 to x<n>
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:n)
# Create a dependent variable y, made by a linear combination of x variables
# y is deliberately not dependent on x3
attach(x_df)
# y is just the sum of all the x variables, plus some random error
x_df$y = rowSums(x_df) + rnorm(n=20, mean=0, sd=0.1)
?lm
cat(sprintf("x%g+", 1:15))
lm_x = lm(y~x1+ x2+ x3+ x4+ x5+ x6+ x7+ x8+ x9+ x10+ x11+ x12+ x13+ x14+ x15, data=x_df)
summary(lm_x)
Sigma[3,]
?princomp
pc_x = princomp(x_df[,(n+1)])
pc_x
pc_x = princomp(x_df[,-(n+1)])
pc_x
set.seed(60005)
n <- 15
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
Sigma
# Generate a matrix 40 draws from this distribution
x_mat = mvrnorm(n=20, mu=rep(1,n), Sigma=Sigma)
# Turn it into a data frame and name the columns x1 to x<n>
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:n)
# Create a dependent variable y, made by a linear combination of x variables
attach(x_df)
# y is just the sum of all the x variables, plus some random error
x_df$y = rowSums(x_df) + rnorm(n=20, mean=0, sd=0.1)
lm_x = lm(y~x1+ x2+ x3+ x4+ x5+ x6+ x7+ x8+ x9+ x10+ x11+ x12+ x13+ x14+ x15, data=x_df)
summary(lm_x)
set.seed(6005)
n <- 15
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
# Generate a matrix 40 draws from this distribution
x_mat = mvrnorm(n=20, mu=rep(1,n), Sigma=Sigma)
# Turn it into a data frame and name the columns x1 to x<n>
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:n)
# Create a dependent variable y, made by a linear combination of x variables
attach(x_df)
# y is just the sum of all the x variables, plus some random error
x_df$y = rowSums(x_df) + rnorm(n=20, mean=0, sd=0.1)
lm_x = lm(y~x1+ x2+ x3+ x4+ x5+ x6+ x7+ x8+ x9+ x10+ x11+ x12+ x13+ x14+ x15, data=x_df)
summary(lm_x)
Sigma
pc_x = princomp(x_df[,-(n+1)])
summary(pc_x)
screeplot(pc_x)
loadings(pc_x)
load_pcx = loadings(pc_x)
class(load_pcx)
names(load_pcx)
load_pcx%*%x_df[,-16]
attr(load_pcx, "Loadings")
?loadings
pc_x$loadings
load_pcx = pc_x$loadings
class(load_pcx)
biplot(pc_x)
as.matrix(load_pcx)
as.matrix(load_pcx)%*%x_mat
dim(as.matrix(load_pcx))
dim(x_mat)
t(x_mat)%*%as.matrix(load_pcx)
dim(t(x_mat))
dim(x_mat)
pc_x_data = x_mat%*%as.matrix(load_pcx)
cor(pc_x_data)
names(pc_x_data)
class(pc_x_data)
pc_x_df = as.data.frame(pc_x_mat)
pc_x_mat = x_mat%*%as.matrix(load_pcx)
# You can see that now the correlations are [almost] zero
# This therefore solves our problem of multicollinearity
cor(pc_x_mat)
pc_x_df = as.data.frame(pc_x_mat)
names(pc_x_df) = sprintf("pc%g", 1:15)
pc_x_df
pc_x
summary(pc_x)
pc_x_df$y = x_df$y
cat(sprintf("pc%g +", 1:9))
pc_lm = lm(y ~ pc1 + pc2 + pc3 + pc4 + pc5 + pc6 + pc7 + pc8 + pc9, data = pc_x_df)
summary(pc_lm)
cat(sprintf("pc%g +", 1:15))
pc_lm_full = lm(y~pc1 + pc2 + pc3 + pc4 + pc5 + pc6 + pc7 + pc8 + pc9 + pc10 + pc11 + pc12 + pc13 + pc14 + pc15, data=pc_x_df)
summary(pc_lm_full)
summary(pc_x)
pc_lm_red = lm(y~pc1 + pc2 + pc3 + pc4 + pc5 + pc6 + pc7 + pc8 + pc9 + pc10 + pc11 + pc12, data=pc_x_df)
summary(pc_lm_red)
summary(lm_x)
pc_x$loadings
0.03*92
3/92
2/92
4/92
0.14*92
13/92
14/92
12/92
79+89
16/184
2/23
(2/23)*92
(21/23)*92
stent_obs = data.frame(survived = c(79,89), died = c(13,3))
row.names(stent_obs) = c("Surgery", "Treatment")
stent_obs
num1 = pt_obs - pc_obs
den1 = sqrt(p_null*(1-p_null)*(2/92))
tstat1_stent = num1/den1
# First way
pc_obs = 13/92
pt_obs = 3/92
p_null = 2/23
num1 = pt_obs - pc_obs
den1 = sqrt(p_null*(1-p_null)*(2/92))
tstat1_stent = num1/den1
tstat1_stent
pnorm(q=tstat1_stent)
pnorm(q=tstat1_stent, lower.tail = T)
2*pnorm(q=tstat1_stent, lower.tail = T)
2*(1-pnorm(q=tstat1_stent, lower.tail = F))
sum_chi_sq_st = 0 # set a running total going
# in the following, tab_obs is the table of observed values and
# tab_exp is the table of expected values
for (i in 1:2){
for (j in 1:2){
tmp = ((stent_obs[i,j] - stent_exp[i,j])^2)/stent_exp[i,j]
sum_chi_sq_st = sum_chi_sq_st + tmp
}
}
stent_exp = data.frame(survived = c(84,84), died = c(8,8))
# in the following, tab_obs is the table of observed values and
# tab_exp is the table of expected values
for (i in 1:2){
for (j in 1:2){
tmp = ((stent_obs[i,j] - stent_exp[i,j])^2)/stent_exp[i,j]
sum_chi_sq_st = sum_chi_sq_st + tmp
}
}
sum_chi_sq_st
1-pchisq(sum_chi_sq_st, df=1)
sum_LR_st = 0 # set a running total going
# in the following, tab_obs is the table of observed values and
# tab_exp is the table of expected values
for (i in 1:2){
for (j in 1:2){
tmp = stent_obs[i,j] * log(stent_obs[i,j]/stent_exp[i,j])
sum_LR_st = sum_LR_st + tmp
}
}
teststat_LR_st = 2*sum_LR_st
teststat_LR_st
1-pchisq(teststat_LR_st, df=1)
# work macbook
setwd("/Users/rachelo/Documents/GitRepos/clinicaltrials")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
