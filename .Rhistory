T_mich = 4*1.5*6
T_epip =  3*5*1.5 + 2*3
L2_epip = 20*10
M = 8*(56/16)
M_CT = 3
P = 30 + 0.25*30 # includes paternity cover for JP
A0 = 9
E = 50
E_CT = 50 # fairly arbitrary - setting and marking coursework for CT4
X = 100
WC = 10
workload_tot = T_mich + T_epip + L2_epip + M + M_CT + P + A0 +E + E_CT + X + WC
workload_scaled = workload_tot / 0.6
workload_scaled
T_mich = 4*1.5*6    # DSSC tutorials michaelmas + easter
T_epip =  3*4*1.5 + 2*3   # Stats modelling + CT4 practicals
L2_epip = 20*10     # CT4 lectures
M = 8*(56/16)    # Decision Theory (assumes both terms?)
M_michonly = 4*(56/16) # DT marking if only Michaelmas
M_CT = 3         # Assignment marking for CT4 - suspect an underestimate!
P = 30 + 0.25*30 # My own project plus paternity cover for JP
A0 = 9           # Advisees
E = 50           # exam and project marking
E_CT = 50        # fairly arbitrary - setting and marking coursework for CT4
X = 100          # Extra stuff
WC = 10          # Workload committee
workload_tot = T_mich + T_epip + L2_epip + M + M_CT + P + A0 +E + E_CT + X + WC
workload_scaled = workload_tot / 0.6
T_mich = 4*1.5*6    # DSSC tutorials michaelmas + easter
T_epip =  3*4*1.5 + 2*3   # Stats modelling + CT4 practicals
L2_epip = 20*10     # CT4 lectures
M = 8*(56/16)    # Decision Theory (assumes both terms?)
M_michonly = 4*(56/16) # DT marking if only Michaelmas
M_CT = 3         # Assignment marking for CT4 - suspect an underestimate!
P = 30 + 0.25*30 # My own project plus paternity cover for JP
A0 = 9           # Advisees
E = 50           # exam and project marking
E_CT = 50        # fairly arbitrary - setting and marking coursework for CT4
X = 100          # Extra stuff
WC = 10          # Workload committee
workload_tot = T_mich + T_epip + L2_epip + M + M_CT + P + A0 +E + E_CT + X + WC
workload_scaled = workload_tot / 0.6
workload_tot_DTmich = T_mich + T_epip + L2_epip + M_michonly + M_CT + P + A0 +E + E_CT + X + WC
workload_scaled_DTmich = workload_tot_DTmich/0.6
workload_scaled
workload_scaled_DTmich
q()
library(maps)
?maps
data("world2MapEnv")
class(world2MapEnv)
data(world2MapEnv)
class(world2MapEnv)
class(world)
data(world)
data("world")
map('world', fill = TRUE, col = 1:10, wrap=c(-180,180) )
map('world', wrap=c(-180,180) )
world = map_data("world")
library(ggplot2)
world = map_data("world")
names(world)
?aes
ggplot(data=world, aes(x=long, y=lat, group = group)) + geom_path()
max(world$group)
?plot
plot(lat~long, data = world[world$group==1,])
plot(lat~long, data = world[world$group==1,], type = "l")
plot(lat~long, data = world[world$group==1,], type = "l", xlim=c(-180,180))
summary(world)
plot(lat~long, data = world[world$group==1,],
type = "l", xlim=c(-180,191), ylim = c(-86, 84))
?lines
for (i in 2:1627){
lines(world$long[world$group==i], world$lat[world$group=2])
for (i in 2:1627){
lines(world$long[world$group==i], world$lat[world$group==i])
}
ggworldplot = ggplot(data=world, aes(x=long, y=lat, group = group)) +
geom_path() +
theme_bw() +
xlab("Longitude") +
ylab("Latitude")
ggworldplot
storm_df = data.frame(
long = rnorm(100, mean=-50, sd=10),
lat = rnorm(100, mean=0, sd=30),
pressure = rnorm(100, mean=10, sd=10)
)
ggworldplot +
geom_point(aes(x=long, y=lat, fill=pressure), alpha=0.5)+
scale_fill_continuous(type = "viridis")
storm_df
ggworldplot +
geom_point(data = storm_df, aes(x=long, y=lat, fill=pressure), alpha=0.5)+
scale_fill_continuous(type = "viridis")
ggworldplot = ggplot(data=world, aes(x=long, y=lat)) +
geom_path(aes(group = group)) +
theme_bw() + # this gets rid of the grey background
xlab("Longitude") +
ylab("Latitude")
ggworldplot
storm_df = data.frame(
long = rnorm(100, mean=-50, sd=10),
lat = rnorm(100, mean=0, sd=30),
pressure = rnorm(100, mean=10, sd=10)
)
ggworldplot +
geom_point(data = storm_df, aes(x=long, y=lat, fill=pressure), alpha=0.5)+
scale_fill_continuous(type = "viridis")
ggworldplot +
geom_point(data = storm_df, aes(x=long, y=lat, col=pressure), alpha=0.5)+
scale_color_continuous(type = "viridis")
storm_df = data.frame(
long = rnorm(100, mean=-50, sd=50),
lat = rnorm(100, mean=0, sd=10),
pressure = rnorm(100, mean=10, sd=10)
)
ggworldplot +
geom_point(data = storm_df, aes(x=long, y=lat, col=pressure), alpha=0.5)+
scale_color_continuous(type = "viridis")
storm_df = data.frame(
long = rnorm(100, mean=-50, sd=5),
lat = rnorm(100, mean=0, sd=10),
pressure = rnorm(100, mean=10, sd=10)
)
ggworldplot +
geom_point(data = storm_df, aes(x=long, y=lat, col=pressure), alpha=0.5)+
scale_color_continuous(type = "viridis")
storm_df = data.frame(
long = rnorm(100, mean=-50, sd=5),
lat = rnorm(100, mean=0, sd=10),
pressure = rnorm(100, mean=100, sd=10)
)
ggworldplot +
geom_point(data = storm_df, aes(x=long, y=lat, col=pressure),
alpha=0.5) +
scale_color_continuous(type = "viridis")
ggworldplot + # add this on to the world map
geom_point(data = storm_df, aes(x=long, y=lat, col=pressure),
alpha=0.3) +
scale_color_continuous(type = "viridis")
ggworldplot + # add this on to the world map
geom_point(data = storm_df, aes(x=long, y=lat, col=pressure),
alpha=0.4) +
scale_color_continuous(type = "viridis")
library(mvnorm)
library(MASS)
?mnrnorm
?mvrnorm
set.seed(60007)
x_cor = diag(4)
for (i in 1:3){
for (j in 2:4){
random_corr = runif(1, min=0, max=1)
x_cor[i,j] = random_corr
x_cor[j,i] = random_corr
}
}
x_mat = mvrnorm(n=20, mu=)
x_cor
is.pd(x_cor)
is.positive.definite(x_cor)
library(matrixcalc)
require(matrixcalc)
install.packages("matrixcalc")
require(matrixcalc)
is.positive.definite(x_cor)
n <- 4
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
is.positive.definite(Sigma)
Sigma
set.seed(60007)
n <- 4
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
Sigma
x_mat = mvrnorm(n=20, mu=1, Sigma=Sigma)
x_mat = mvrnorm(n=20, mu=c(1,2,3,4), Sigma=Sigma)
set.seed(60007)
n <- 4
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
x_mat = mvrnorm(n=20, mu=1:4, Sigma=Sigma)
x_mat
names(x_df) = sprintf("x%g", 1:4)
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:4)
x_df
# Create a dependent variable y, made by a linear combination of x variables
# y is deliberately not dependent on x3
attach(x_df)
x_df$y = 3*x1 + 2*x2 - x4
x_df
lm_x = lm(y~x1+x2+x3+x4, data=x_df)
summary(lm_x)
# Create a dependent variable y, made by a linear combination of x variables
# y is deliberately not dependent on x3
attach(x_df)
x_df$y = 3*x1 + 2*x2 - x4 + rnorm(n=20, mean=0, sd=0.1)
lm_x = lm(y~x1+x2+x3+x4, data=x_df)
summary(lm_x)
set.seed(60007)
n <- 15
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
# Generate a matrix 40 draws from this distribution
x_mat = mvrnorm(n=20, mu=1:n, Sigma=Sigma)
# Turn it into a data frame and name the columns x1 to x<n>
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:n)
# Create a dependent variable y, made by a linear combination of x variables
# y is deliberately not dependent on x3
attach(x_df)
Sigma
set.seed(60007)
n <- 15
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
# Generate a matrix 40 draws from this distribution
x_mat = mvrnorm(n=20, mu=rep(1,n), Sigma=Sigma)
# Turn it into a data frame and name the columns x1 to x<n>
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:n)
# Create a dependent variable y, made by a linear combination of x variables
# y is deliberately not dependent on x3
attach(x_df)
# y is just the sum of all the x variables, plus some random error
x_df$y = rowSums(x_df) + rnorm(n=20, mean=0, sd=0.1)
?lm
cat(sprintf("x%g+", 1:15))
lm_x = lm(y~x1+ x2+ x3+ x4+ x5+ x6+ x7+ x8+ x9+ x10+ x11+ x12+ x13+ x14+ x15, data=x_df)
summary(lm_x)
Sigma[3,]
?princomp
pc_x = princomp(x_df[,(n+1)])
pc_x
pc_x = princomp(x_df[,-(n+1)])
pc_x
set.seed(60005)
n <- 15
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
Sigma
# Generate a matrix 40 draws from this distribution
x_mat = mvrnorm(n=20, mu=rep(1,n), Sigma=Sigma)
# Turn it into a data frame and name the columns x1 to x<n>
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:n)
# Create a dependent variable y, made by a linear combination of x variables
attach(x_df)
# y is just the sum of all the x variables, plus some random error
x_df$y = rowSums(x_df) + rnorm(n=20, mean=0, sd=0.1)
lm_x = lm(y~x1+ x2+ x3+ x4+ x5+ x6+ x7+ x8+ x9+ x10+ x11+ x12+ x13+ x14+ x15, data=x_df)
summary(lm_x)
set.seed(6005)
n <- 15
A <- matrix(runif(n^2)*2-1, ncol=n)
Sigma <- t(A) %*% A
# Generate a matrix 40 draws from this distribution
x_mat = mvrnorm(n=20, mu=rep(1,n), Sigma=Sigma)
# Turn it into a data frame and name the columns x1 to x<n>
x_df = as.data.frame(x_mat)
names(x_df) = sprintf("x%g", 1:n)
# Create a dependent variable y, made by a linear combination of x variables
attach(x_df)
# y is just the sum of all the x variables, plus some random error
x_df$y = rowSums(x_df) + rnorm(n=20, mean=0, sd=0.1)
lm_x = lm(y~x1+ x2+ x3+ x4+ x5+ x6+ x7+ x8+ x9+ x10+ x11+ x12+ x13+ x14+ x15, data=x_df)
summary(lm_x)
Sigma
pc_x = princomp(x_df[,-(n+1)])
summary(pc_x)
screeplot(pc_x)
loadings(pc_x)
load_pcx = loadings(pc_x)
class(load_pcx)
names(load_pcx)
load_pcx%*%x_df[,-16]
attr(load_pcx, "Loadings")
?loadings
pc_x$loadings
load_pcx = pc_x$loadings
class(load_pcx)
biplot(pc_x)
as.matrix(load_pcx)
as.matrix(load_pcx)%*%x_mat
dim(as.matrix(load_pcx))
dim(x_mat)
t(x_mat)%*%as.matrix(load_pcx)
dim(t(x_mat))
dim(x_mat)
pc_x_data = x_mat%*%as.matrix(load_pcx)
cor(pc_x_data)
names(pc_x_data)
class(pc_x_data)
pc_x_df = as.data.frame(pc_x_mat)
pc_x_mat = x_mat%*%as.matrix(load_pcx)
# You can see that now the correlations are [almost] zero
# This therefore solves our problem of multicollinearity
cor(pc_x_mat)
pc_x_df = as.data.frame(pc_x_mat)
names(pc_x_df) = sprintf("pc%g", 1:15)
pc_x_df
pc_x
summary(pc_x)
pc_x_df$y = x_df$y
cat(sprintf("pc%g +", 1:9))
pc_lm = lm(y ~ pc1 + pc2 + pc3 + pc4 + pc5 + pc6 + pc7 + pc8 + pc9, data = pc_x_df)
summary(pc_lm)
cat(sprintf("pc%g +", 1:15))
pc_lm_full = lm(y~pc1 + pc2 + pc3 + pc4 + pc5 + pc6 + pc7 + pc8 + pc9 + pc10 + pc11 + pc12 + pc13 + pc14 + pc15, data=pc_x_df)
summary(pc_lm_full)
summary(pc_x)
pc_lm_red = lm(y~pc1 + pc2 + pc3 + pc4 + pc5 + pc6 + pc7 + pc8 + pc9 + pc10 + pc11 + pc12, data=pc_x_df)
summary(pc_lm_red)
summary(lm_x)
pc_x$loadings
getwd()
# work macbook
setwd("/Users/rachelo/Documents/GitRepos/clinicaltrials")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
library(medicaldata)
data("polyps")
summary(polyps)
lm(number12m ~ sex + age+baseline + treatment, data=polyps)
lmlin_polyps = lm(number12m ~ sex + age+baseline + treatment, data=polyps)
summary(lmlin_polyps)
length(resid_capt)
resid_capt = resid(lm_capt)
length(resid_capt)
dim(df_hommel)
df_hommel
df_hommel$resid= resid_capt
ggplot(data = df_hommel, aes(x=baseline, y=resid, col=arm)) + geom_point()
ggplot(data = df_hommel, aes(x=baseline, y=resid, col=arm)) +
geom_point() +
geom_hline(yintercept=0)+
xlab("Baseline")+
ylab("Residual")
names(polyps)
?polyps
install.package("HSAUR")
install.packages("HSAUR")
library(HSAUR)
data("BtheB")
summary(BtheB)
lm_btheb = lm(bdi.8m ~ drug + length + treatment + bdi.pre, data = BtheB)
summary(lm_btheb)
lm_btheb = lm(bdi.2m ~ drug + length + treatment + bdi.pre, data = BtheB)
summary(lm_btheb)
lm_btheb = lm(bdi.4m ~ drug + length + treatment + bdi.pre, data = BtheB)
summary(lm_btheb)
data(epilepsy)
lm_epi = lm(seizure.rate ~ treatment + base + age, data= epilepsy)
summary(lm_epi)
lm_epi_int = lm(seizure.rate ~ (treatment + base + age):(treatment + base + age), data=epilepsy)
summary(lm_epi_int)
ggplot(data = epilepsy, aes(x=base, y=seizure.rate, col=treatment)) + geom_point()
ggplot(data=acu_df, aes(x=score_baseline, y=score_1year, col=group)) +
geom_point() +
geom_abline(
slope = coef(lm_acu_lin)[["score_baseline"]],
intercept = coef(lm_acu_lin)[["(Intercept)"]],
colour = "red") +
geom_abline(
slope = coef(lm_acu_lin)[["score_baseline"]],
intercept = coef(lm_acu_lin)[["(Intercept)"]] + coef(lm_acu_lin)[["group1"]],
colour = "darkturquoise")
```
citation(medicaldata)
library(medicaldata)
citation(medicaldata)
citation("medicaldata")
citeR()
citation()
citation("medicaldata")
wl_df = read.csv("data/lead_adults.csv)
```{r, echo=T}
wl_df = read.csv("data/lead_adults.csv", header=T)
```{r, echo=T}
wl_df = read.csv(file = "data/lead_adults.csv", header=T)
summary(wl_df)
class(wl_df$Group) = "factor"
wl_df$Group = as.factor(wl_df$Group)
summary(wl_df)
wl_df$Group = as.factor(wl_df$Group)
names(wl_df)[c(3,4)] = c("Age", "Sex")
wl_df$Group = as.factor(wl_df$Group)
names(wl_df)[c(3,4)] = c("Age", "Sex")
wl_df$Sex = as.factor(wl_df$Sex)
summary(wl_df)
wl_df$Group = as.factor(wl_df$Group)
names(wl_df)[c(3,4)] = c("Age", "Sex")
wl_df$Sex = as.factor(wl_df$Sex)
names(wl_df)[c(9,11)] = c("baselineBMI", "postBMI")
summary(wl_df)
lm_lean = lm(postBMI ~ Age + Sex + Group + baselineBMI, data = wl_df)
summary(lm_lean)
lm_lean = lm(postBMI ~ Age + Sex + Group + baselineBMI, data = wl_df)
lm_lean_int = lm(postBMI ~ (Age + Sex + Group + baselineBMI):(Age + Sex + Group + baselineBMI), data = wl_df)
summary(lm_lean_int)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
bookdown::render_book("index.Rmd", "bookdown::gitbook")
install.packages("faraway")
library(faraway)
data("toenail")
summary(toenail)
bookdown::render_book("index.Rmd", "bookdown::gitbook")
q()
